---
title: "ACT-Horizon - Complexity Theory Translation"
---

# ACT-Horizon: Epistemic Limits and Uncomputability

## Overview

This document provides a complete complexity-theoretic translation of the ACT-Horizon metatheorem (Epistemic Horizon Principle) from the hypostructure framework. The theorem establishes that information acquisition is bounded by fundamental limits: the data processing inequality, entropy production, and thermodynamic dissipation. In complexity theory, this corresponds to **Epistemic Limits**: information-theoretic and computability-theoretic bounds on prediction.

**Original Theorem Reference:** {prf:ref}`mt-act-horizon`

**Central Translation:** Systems admit epistemic horizons beyond which prediction is uncomputable $\longleftrightarrow$ **Uncomputability**: The halting problem, Rice's theorem, and information-theoretic limits on prediction establish fundamental boundaries to what can be known about computational systems.

---

## Complexity Theory Statement

**Theorem (Epistemic Limits on Prediction).**
For computational systems with sufficient complexity, there exist fundamental prediction horizons beyond which no algorithm can reliably forecast behavior.

**Formal Statement.** Let $M$ be a Turing machine and $\mathcal{P}$ be a prediction problem about $M$'s behavior. Define:

1. **Halting Horizon:** The predicate $\text{HALT}(M, x)$ = "does $M$ halt on input $x$?" is undecidable.

2. **Rice's Barrier:** For any non-trivial semantic property $P$ of computable functions, $\{e : \phi_e \text{ has property } P\}$ is undecidable.

3. **Kolmogorov Barrier:** For any string $x$, computing its Kolmogorov complexity $K(x)$ is uncomputable.

4. **Information-Theoretic Bound:** For any prediction channel $X \to Y \to \hat{X}$:
   $$I(X; \hat{X}) \leq I(X; Y)$$
   Prediction accuracy is bounded by channel capacity.

**Guarantees:**
1. **Fundamental undecidability:** Certain prediction problems have no algorithmic solution
2. **Information loss:** Entropy production degrades predictive information
3. **Horizon existence:** Beyond certain thresholds, prediction becomes impossible
4. **Barrier certification:** Undecidability proofs provide certificates of limitation

---

## Terminology Translation Table

| Hypostructure Term | Complexity Theory Equivalent |
|--------------------|------------------------------|
| Epistemic horizon | Undecidability barrier / prediction horizon |
| Data processing inequality $I(X;Z) \leq I(X;Y)$ | Channel capacity bound on prediction |
| Landauer bound $k_B T \ln 2$ | Minimum computational cost per bit |
| KS entropy $h_\mu$ | Algorithmic entropy production rate |
| Lyapunov exponents $\lambda_i > 0$ | Exponential sensitivity / chaos |
| Entropy production $\Sigma(T_*)$ | Information loss over computation |
| Channel capacity $C_\Phi(\lambda)$ | Maximum transmissible information |
| Mutual information $I(u_0; u(t))$ | Predictive information preservation |
| Singularity detection | Halting detection |
| Information barrier $K_{\text{Epi}}^{\text{blk}}$ | Undecidability certificate |
| Capacity permit $\mathrm{Cap}_H$ | Decidable fragment / promise problem |
| Dissipation $D_E$ | Computational irreversibility |
| Observation failure mode D.E | Self-reference paradox |
| Measurement failure mode D.C | Observer effect / uncertainty |
| Pesin's formula $h_\mu = \sum \lambda_i$ | Entropy-complexity correspondence |
| Initial condition $u_0$ | Program input $x$ |
| Time evolution $u(t)$ | Computation trace $M^t(x)$ |
| Blow-up time $T_*$ | Halting time (if exists) |

---

## Epistemic Horizons in Computability Theory

### The Halting Problem as Epistemic Horizon

**Definition (Halting Problem).** The halting problem $\text{HALT}$ asks: given a Turing machine $M$ and input $x$, does $M$ halt on $x$?

**Theorem (Turing 1936).** The halting problem is undecidable. There is no algorithm $H$ such that:
$$H(M, x) = \begin{cases} 1 & \text{if } M \text{ halts on } x \\ 0 & \text{otherwise} \end{cases}$$

**Epistemic Horizon Interpretation:**
- The halting time $T_*(M, x)$ is the "blow-up time" for computation
- Predicting whether $T_* < \infty$ is undecidable
- This is the fundamental epistemic horizon for computation

### Rice's Theorem as Universal Barrier

**Theorem (Rice 1953).** For any non-trivial property $P$ of partial computable functions:
$$\{e : \phi_e \text{ has property } P\} \text{ is undecidable}$$

where "non-trivial" means there exist $e_1, e_2$ with $\phi_{e_1} \in P$ and $\phi_{e_2} \notin P$.

**Epistemic Horizon Interpretation:**
- No semantic property of programs can be decided algorithmically
- This generalizes the halting horizon to all non-trivial questions
- The barrier is universal: applies to termination, correctness, equivalence, etc.

---

## Proof Sketch: Information-Theoretic Undecidability

### Setup: Computation as Information Channel

**Definitions:**

1. **Computational Channel:** A computation $M(x)$ defines a channel:
   $$X \xrightarrow{\text{encode}} M \xrightarrow{\text{compute}} Y \xrightarrow{\text{predict}} \hat{X}$$
   where $X$ is the input, $Y$ is the trace/output, $\hat{X}$ is the prediction.

2. **Predictive Information:** The mutual information $I(X; \hat{X})$ measures prediction quality.

3. **Channel Capacity:** The maximum information transmissible through computation:
   $$C = \max_{p(X)} I(X; Y)$$

4. **Algorithmic Entropy:** The Kolmogorov complexity $K(x)$ measures intrinsic information content.

**Resource Functionals (Entropy Production Analogue):**

Define the computational entropy production at step $t$:
$$\Sigma(t) := H(M^0(x)) - I(M^0(x); M^t(x))$$

This measures information lost during computation (irreversibility).

---

### Step 1: Halting Problem via Diagonalization

**Theorem (Turing).** HALT is undecidable.

**Proof (Epistemic Horizon Construction).**

*Step 1.1 (Assume decidability).* Suppose $H(M, x)$ decides halting.

*Step 1.2 (Construct diagonal machine).* Define $D(M)$:
```
D(M):
  if H(M, M) = 1:  // M halts on itself
    loop forever
  else:
    halt
```

*Step 1.3 (Self-reference creates paradox).* Consider $D(D)$:
- If $D(D)$ halts, then $H(D, D) = 1$, so $D(D)$ loops. Contradiction.
- If $D(D)$ loops, then $H(D, D) = 0$, so $D(D)$ halts. Contradiction.

*Step 1.4 (Epistemic horizon certificate).* The contradiction establishes:
$$K_{\text{Epi}}^{\text{blk}} = \{\text{HALT is undecidable}\}$$

**Hypostructure Correspondence:**
- $D$ corresponds to a system approaching singularity
- Self-reference creates an epistemic horizon
- No observer (algorithm) can see past this horizon

---

### Step 2: Data Processing Inequality as Prediction Bound

**Lemma (Data Processing Inequality).** For any Markov chain $X \to Y \to Z$:
$$I(X; Z) \leq I(X; Y)$$

**Application to Computation:**

*Step 2.1 (Computation as Markov chain).* For computation $M$ with input $x$:
$$x \to M^1(x) \to M^2(x) \to \cdots \to M^t(x)$$

Each step is a Markov transition.

*Step 2.2 (Prediction bound).* Any predictor $P$ using only $M^t(x)$ satisfies:
$$I(x; P(M^t(x))) \leq I(x; M^t(x))$$

*Step 2.3 (Information loss).* If computation is irreversible (entropy-producing):
$$I(x; M^t(x)) < I(x; M^{t-1}(x)) < \cdots < H(x)$$

*Step 2.4 (Horizon formation).* When $I(x; M^t(x)) \to 0$, prediction becomes impossible:
$$\lim_{t \to \infty} I(x; M^t(x)) = 0 \Rightarrow \text{epistemic horizon at } t = \infty$$

**Certificate:**
$$K_{\text{Epi}}^{\text{blk}} = \{I_{\max} = I(x; M^{t_0}(x)), \text{ horizon at } t_* \text{ where } I \to 0\}$$

---

### Step 3: Kolmogorov Complexity and Incompressibility

**Definition (Kolmogorov Complexity).** The Kolmogorov complexity of string $x$ is:
$$K(x) = \min\{|p| : U(p) = x\}$$
where $U$ is a universal Turing machine and $p$ is a program.

**Theorem (Uncomputability of $K$).** There is no algorithm to compute $K(x)$.

**Proof (Information-Theoretic).**

*Step 3.1 (Berry paradox formalization).* Suppose $\text{KOLM}$ computes $K(x)$.

*Step 3.2 (Construct paradoxical program).* For large $n$, consider:
```
P_n:
  for each string x of length <= n:
    if KOLM(x) >= n:
      output x and halt
```

*Step 3.3 (Complexity contradiction).* $P_n$ outputs some $x$ with $K(x) \geq n$.
But $|P_n| = O(\log n)$, so $K(x) \leq |P_n| + O(1) = O(\log n) < n$ for large $n$.

*Step 3.4 (Epistemic horizon).* Kolmogorov complexity is uncomputable:
$$K_{\text{Epi}}^{\text{blk}} = \{K(x) \text{ is uncomputable}\}$$

**Connection to Entropy:**
- $K(x) \approx H(X)$ for random $x$ (algorithmic-Shannon correspondence)
- Incompressible strings have maximal entropy
- Predicting incompressible data is impossible

---

### Step 4: Rice's Theorem via Reduction

**Theorem (Rice).** Any non-trivial semantic property $P$ of programs is undecidable.

**Proof (Epistemic Horizon Generalization).**

*Step 4.1 (Setup).* Let $P$ be non-trivial: $\exists e_0, e_1$ with $\phi_{e_0} \in P$, $\phi_{e_1} \notin P$.

*Step 4.2 (Reduction from HALT).* Given $(M, x)$, construct $M'$:
```
M'(y):
  run M on x
  if M halts:
    return phi_{e_1}(y)
  else:
    loop forever (never reached if M doesn't halt)
```

*Step 4.3 (Analysis).*
- If $M(x)$ halts: $\phi_{M'} = \phi_{e_1} \notin P$
- If $M(x)$ loops: $\phi_{M'} = \emptyset$ (undefined everywhere)

*Step 4.4 (Decide P decides HALT).* If we could decide $P$:
- $M' \in P \Rightarrow M(x)$ loops (since $\phi_{e_1} \notin P$)
- $M' \notin P \Rightarrow M(x)$ halts

This decides HALT. Contradiction.

**Certificate:**
$$K_{\text{Epi}}^{\text{blk}} = \{P \text{ undecidable for any non-trivial semantic } P\}$$

---

### Step 5: Prediction Horizons in Dynamical Systems

**Connection to Lyapunov Exponents:**

*Step 5.1 (Chaotic systems).* For a dynamical system with Lyapunov exponent $\lambda > 0$:
$$\|x(t) - x'(t)\| \approx \|x(0) - x'(0)\| \cdot e^{\lambda t}$$

*Step 5.2 (Prediction horizon).* Initial uncertainty $\delta$ grows to system scale $L$ at:
$$T_{\text{predict}} = \frac{1}{\lambda} \ln\left(\frac{L}{\delta}\right)$$

*Step 5.3 (Finite precision barrier).* With $n$ bits of precision ($\delta = 2^{-n}$):
$$T_{\text{predict}} = \frac{n \ln 2}{\lambda}$$

Beyond $T_{\text{predict}}$, prediction is no better than random.

*Step 5.4 (Computational analogue).* For computation with "algorithmic Lyapunov exponent":
- Small input perturbations cause exponentially divergent outputs
- Prediction horizon exists even for decidable systems
- Chaotic Turing machines exhibit computational unpredictability

---

## Connections to Computability Theory

### 1. The Halting Problem

**Classical Result.** The halting problem is RE-complete (recursively enumerable but not recursive).

**Epistemic Horizon Translation:**

| Halting Problem Aspect | Hypostructure Analogue |
|------------------------|------------------------|
| Undecidability | Epistemic horizon exists |
| Semi-decidability (RE) | One-sided prediction possible |
| Diagonalization | Self-reference creates barrier |
| Reductions | Information-preserving maps |
| Oracle hierarchy | Graded epistemic access |

**Certificate Correspondence:**
- $K_{\text{Epi}}^-$: Halting is semi-decidable (can detect halting, not non-halting)
- $K_{\text{Epi}}^{\text{blk}}$: Full prediction is blocked (undecidable)
- $K_{\text{Epi}}^{\sim}$: Effective prediction with oracles

### 2. The Arithmetical Hierarchy

**Definition.** The arithmetical hierarchy stratifies undecidability:
- $\Sigma_0 = \Pi_0 = \Delta_0$ = recursive sets
- $\Sigma_{n+1}$ = sets definable by $\exists^\infty$ over $\Pi_n$
- $\Pi_{n+1}$ = sets definable by $\forall^\infty$ over $\Sigma_n$

**Hierarchy of Epistemic Horizons:**

| Level | Example | Epistemic Access |
|-------|---------|------------------|
| $\Sigma_0 = \Pi_0$ | Finite sets | Full prediction |
| $\Sigma_1$ (RE) | Halting (positive) | Semi-prediction |
| $\Pi_1$ (co-RE) | Non-halting | Complementary semi-prediction |
| $\Sigma_2$ | $\text{Tot} = \{e : \phi_e \text{ total}\}$ | Double quantifier horizon |
| Higher levels | More complex properties | Deeper horizons |

### 3. Chaitin's Omega and Algorithmic Information

**Definition (Chaitin's Omega).** The halting probability:
$$\Omega = \sum_{\{p : U(p) \downarrow\}} 2^{-|p|}$$

**Properties:**
- $\Omega$ is a well-defined real number in $[0, 1]$
- $\Omega$ is algorithmically random (incompressible)
- $\Omega$ encodes all halting information

**Epistemic Horizon Interpretation:**
- The first $n$ bits of $\Omega$ solve all halting problems up to size $n$
- But computing $\Omega_n$ requires solving $\Omega(2^n)$ halting problems
- Information-theoretic barrier: cannot compress halting information

**Certificate:**
$$K_{\text{Epi}}^{\text{blk}} = \{K(\Omega \upharpoonright n) \geq n - O(1)\}$$

$\Omega$ is maximally unpredictable.

### 4. Godel's Incompleteness and Provability Horizons

**Theorem (Godel 1931).** Any consistent formal system $F$ capable of arithmetic cannot prove its own consistency.

**Epistemic Horizon Translation:**
- **Self-reference** $\leftrightarrow$ Diagonalization
- **Consistency** $\leftrightarrow$ Non-contradiction
- **Provability** $\leftrightarrow$ Algorithmic verification
- **True but unprovable** $\leftrightarrow$ Beyond epistemic horizon

**Godel Sentence:**
$$G_F \equiv \text{"} G_F \text{ is not provable in } F \text{"}$$

- If $F$ proves $G_F$: $F$ is inconsistent
- If $F$ doesn't prove $G_F$: $G_F$ is true but unprovable

**Certificate:**
$$K_{\text{Epi}}^{\text{blk}} = \{G_F \text{ unprovable in } F\}$$

---

## Prediction Complexity Classes

### Predictability Hierarchy

| Class | Prediction Capability | Example |
|-------|----------------------|---------|
| **P-predictable** | Polynomial-time prediction | Finite automata behavior |
| **BPP-predictable** | Probabilistic polynomial prediction | Randomized protocols |
| **PSPACE-predictable** | Space-bounded prediction | Game outcomes |
| **RE-predictable** | Semi-decidable prediction | Halting (positive) |
| **Unpredictable** | No algorithmic prediction | General halting |

### Oracle Hierarchies and Relative Prediction

**Definition (Relativized Prediction).** With oracle $A$, define:
$$\text{HALT}^A = \{(M, x) : M^A \text{ halts on } x\}$$

**Jump Operator:**
$$A' = \text{HALT}^A$$

**Hierarchy of Horizons:**
- $\emptyset$ = recursive sets (no horizon)
- $\emptyset'$ = halting problem (first horizon)
- $\emptyset''$ = halting of halting machines (second horizon)
- $\emptyset^{(n)}$ = $n$-th jump (horizon at level $n$)
- $\emptyset^{(\omega)}$ = $\omega$-th jump (limit horizon)

**Certificate Grading:**
$$K_{\text{Epi}}^{(n)} = \{\text{prediction requires } \emptyset^{(n)} \text{ oracle}\}$$

---

## Certificate Construction

### Undecidability Certificate

```
K_Halting = {
    mode: "Epistemic_Horizon",
    mechanism: "Diagonalization",

    barrier: {
        problem: "HALT(M, x)",
        type: "RE-complete",
        certificate: "Diagonal argument",
        witness: "D(D) paradox"
    },

    information_bound: {
        channel: "M(x) computation",
        capacity: "finite bits per step",
        horizon: "halting time undecidable"
    },

    reductions: {
        from: ["HALT"],
        to: ["Any non-trivial semantic property"],
        type: "many-one"
    },

    certificate: {
        type: "K_Epi^blk",
        payload: {
            undecidable: true,
            semi_decidable: true,
            hierarchy_level: "Sigma_1"
        }
    },

    literature: "Turing 1936"
}
```

### Rice's Theorem Certificate

```
K_Rice = {
    mode: "Universal_Barrier",
    mechanism: "Semantic_Undecidability",

    barrier: {
        scope: "All non-trivial properties P",
        condition: "P semantic (depends only on phi_e)",
        certificate: "Reduction from HALT"
    },

    universality: {
        termination: "undecidable",
        correctness: "undecidable",
        equivalence: "undecidable",
        complexity: "undecidable (Blum)"
    },

    exceptions: {
        syntactic_properties: "may be decidable",
        trivial_properties: "vacuously decidable"
    },

    certificate: {
        type: "K_Epi^blk",
        payload: {
            universal: true,
            all_semantic_P: "undecidable"
        }
    },

    literature: "Rice 1953"
}
```

### Kolmogorov Complexity Certificate

```
K_Kolmogorov = {
    mode: "Algorithmic_Information",
    mechanism: "Berry_Paradox",

    barrier: {
        function: "K(x) = min{|p| : U(p) = x}",
        type: "uncomputable",
        certificate: "Self-reference paradox"
    },

    information_theory: {
        entropy_correspondence: "K(x) â‰ˆ H(X) for random x",
        incompressibility: "Most strings incompressible",
        randomness: "K(x) >= |x| - O(1) defines randomness"
    },

    prediction_bound: {
        random_strings: "unpredictable",
        compression: "impossible for random data",
        pattern_detection: "no universal algorithm"
    },

    certificate: {
        type: "K_Epi^blk",
        payload: {
            K_uncomputable: true,
            lower_bound_uncomputable: true
        }
    },

    literature: "Kolmogorov 1965, Chaitin 1966"
}
```

### Data Processing Inequality Certificate

```
K_DataProcessing = {
    mode: "Information_Degradation",
    mechanism: "Markov_Chain_Bound",

    inequality: {
        statement: "I(X; Z) <= I(X; Y) for X -> Y -> Z",
        meaning: "Information cannot increase through processing"
    },

    computation_application: {
        input: "X = program input",
        computation: "Y = intermediate state",
        prediction: "Z = prediction attempt",
        bound: "I(input; prediction) <= I(input; state)"
    },

    entropy_production: {
        lyapunov: "lambda > 0 implies chaos",
        pesin: "h_mu = sum(lambda_i) for positive exponents",
        information_loss: "Sigma(t) = integral h_mu dt"
    },

    horizon_formation: {
        condition: "I(X; M^t(X)) -> 0 as t -> infinity",
        interpretation: "All predictive information lost"
    },

    certificate: {
        type: "K_Epi^blk",
        payload: {
            I_max: "channel capacity",
            h_mu: "entropy rate",
            horizon_time: "t where I -> 0"
        }
    },

    literature: "Cover-Thomas 2006"
}
```

---

## Quantitative Bounds

### Uncomputability Degree

| Problem | Degree | Horizon Level |
|---------|--------|---------------|
| Halting problem | $\mathbf{0}'$ | First jump |
| Totality | $\mathbf{0}''$ | Second jump |
| Finiteness | $\mathbf{0}''$ | Second jump |
| Cofinality | $\mathbf{0}'''$ | Third jump |
| Index sets | Various | Hierarchy-dependent |

### Information-Theoretic Bounds

| Bound | Formula | Interpretation |
|-------|---------|----------------|
| Data processing | $I(X;Z) \leq I(X;Y)$ | Prediction bounded by channel |
| Landauer | $E \geq k_B T \ln 2$ per bit erased | Thermodynamic cost of computation |
| Pesin | $h_\mu = \sum \lambda_i^+$ | Entropy from chaos |
| Prediction horizon | $T \sim \frac{n \ln 2}{\lambda}$ | Bits $\to$ prediction time |
| Kolmogorov | $K(x) \leq |x| + O(1)$ | Complexity bounded by length |

### Hierarchy Depths

| Level | Oracle | Example Problem |
|-------|--------|-----------------|
| $\Sigma_1$ | $\emptyset'$ | Halting |
| $\Pi_1$ | $\emptyset'$ | Non-halting |
| $\Sigma_2$ | $\emptyset''$ | Eventually halting |
| $\Pi_2$ | $\emptyset''$ | Total functions |
| $\Sigma_n$ | $\emptyset^{(n)}$ | $n$-quantifier existence |
| $\Pi_n$ | $\emptyset^{(n)}$ | $n$-quantifier universality |

---

## Physical Interpretation

### Thermodynamic Computation

**Landauer's Principle:**
- Erasing one bit costs at least $k_B T \ln 2$ energy
- Irreversible computation produces entropy
- Information destruction is physical

**Computational Irreversibility:**
- Most computations are logically irreversible (many-to-one)
- Irreversibility implies information loss
- Information loss implies prediction degradation

**Bennett's Resolution:**
- Reversible computation is possible (zero erasure cost)
- But observation requires copy $\to$ eventual erasure
- Epistemic horizon has thermodynamic cost

### Chaotic Dynamics and Prediction

**Sensitivity to Initial Conditions:**
- Lyapunov exponent $\lambda > 0$: perturbations grow as $e^{\lambda t}$
- Prediction horizon: $T_{\text{predict}} \sim \frac{1}{\lambda} \ln \frac{L}{\delta}$
- Beyond horizon: prediction no better than random

**Algorithmic Chaos:**
- Some Turing machines exhibit chaotic behavior
- Small input changes $\to$ large output changes
- Undecidability as "infinite Lyapunov exponent"

**Computational vs Physical Chaos:**

| Physical Chaos | Computational Chaos |
|----------------|---------------------|
| Finite Lyapunov $\lambda$ | Possibly infinite (undecidability) |
| Continuous state space | Discrete configurations |
| Deterministic but unpredictable | Deterministic but uncomputable |
| Prediction horizon finite | Prediction horizon may be $\infty$ |

---

## Extended Connections

### 1. Algorithmic Randomness

**Martin-Lof Randomness:** A sequence $x$ is random if it passes all computable statistical tests.

**Equivalence:** $x$ is ML-random $\Leftrightarrow$ $K(x \upharpoonright n) \geq n - O(1)$.

**Epistemic Interpretation:**
- Random sequences are maximally unpredictable
- No algorithm can compress them
- They lie beyond all epistemic horizons for pattern detection

### 2. Computational Learning Theory

**No Free Lunch Theorem:** No universal learning algorithm outperforms random guessing across all problems.

**PAC Learning Limits:** Some concept classes are not PAC-learnable without additional structure.

**Connection to Epistemic Horizons:**
- Learning requires inductive bias
- Without bias, prediction horizon is immediate
- Decidable fragments correspond to learnable classes

### 3. Cryptographic Unpredictability

**Pseudorandomness:** Sequences indistinguishable from random to polynomial-time algorithms.

**One-Way Functions:** Functions easy to compute, hard to invert.

**Epistemic Horizon Interpretation:**
- Cryptography exploits computational epistemic horizons
- Adversary cannot predict/invert in polynomial time
- Security = prediction bounded by computational limits

---

## Conclusion

The ACT-Horizon metatheorem translates to complexity theory as the **fundamental limits on prediction**:

**Hypostructure Statement:**
$$K_{\text{Epi}}^{\text{blk}} \text{ with payload } (I_{\max}, h_\mu, k_B T \ln 2)$$

**Complexity Translation:**
$$\text{Undecidability} + \text{Data Processing Inequality} + \text{Algorithmic Information Bounds}$$

The key insight is that **epistemic horizons emerge from fundamental limits**:

1. **Halting Problem:** Self-reference creates undecidability
2. **Rice's Theorem:** All semantic properties face this barrier
3. **Kolmogorov Complexity:** Algorithmic randomness is maximal unpredictability
4. **Data Processing:** Information can only degrade through channels
5. **Chaos:** Exponential sensitivity creates prediction horizons

**The Epistemic Horizon Certificate:**

$$K_{\text{Epi}}^{\text{blk}} = \begin{cases}
K_{\text{Undecidable}} & \text{halting-type problems} \\
K_{\text{Rice}} & \text{semantic properties} \\
K_{\text{Kolmogorov}} & \text{algorithmic information} \\
K_{\text{DataProcessing}} & \text{channel capacity limits} \\
K_{\text{Chaos}} & \text{dynamical prediction horizons}
\end{cases}$$

**Prevented Failure Modes:**
- **D.E (Observation):** Self-reference paradoxes
- **D.C (Measurement):** Information-theoretic bounds

The hypostructure ACT-Horizon theorem reveals that epistemic limits are not merely practical obstacles but **fundamental barriers** arising from the nature of computation, information, and self-reference.

---

## Literature

1. **Turing, A.M. (1936).** "On Computable Numbers, with an Application to the Entscheidungsproblem." *Proceedings of the London Mathematical Society.* *Original undecidability result.*

2. **Rice, H.G. (1953).** "Classes of Recursively Enumerable Sets and Their Decision Problems." *Transactions of the AMS.* *Universal semantic undecidability.*

3. **Kolmogorov, A.N. (1965).** "Three Approaches to the Quantitative Definition of Information." *Problems of Information Transmission.* *Algorithmic information theory.*

4. **Chaitin, G.J. (1966).** "On the Length of Programs for Computing Finite Binary Sequences." *JACM.* *Independent development of algorithmic information.*

5. **Cover, T.M. & Thomas, J.A. (2006).** *Elements of Information Theory* (2nd ed.). Wiley. *Data processing inequality and channel capacity.*

6. **Landauer, R. (1961).** "Irreversibility and Heat Generation in the Computing Process." *IBM Journal of Research and Development.* *Thermodynamic cost of computation.*

7. **Bennett, C.H. (1982).** "The Thermodynamics of Computation---A Review." *International Journal of Theoretical Physics.* *Reversible computation and thermodynamics.*

8. **Pesin, Ya.B. (1977).** "Characteristic Lyapunov Exponents and Smooth Ergodic Theory." *Russian Mathematical Surveys.* *Entropy-exponent correspondence.*

9. **Godel, K. (1931).** "Uber formal unentscheidbare Satze der Principia Mathematica und verwandter Systeme I." *Monatshefte fur Mathematik.* *Incompleteness theorems.*

10. **Rogers, H. (1967).** *Theory of Recursive Functions and Effective Computability.* McGraw-Hill. *Standard computability theory reference.*

11. **Li, M. & Vitanyi, P. (2008).** *An Introduction to Kolmogorov Complexity and Its Applications* (3rd ed.). Springer. *Comprehensive algorithmic information theory.*

12. **Sipser, M. (2012).** *Introduction to the Theory of Computation* (3rd ed.). Cengage. *Modern computability and complexity.*
